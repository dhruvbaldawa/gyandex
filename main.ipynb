{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "urls = [\n",
    "    # \"https://kellblog.com/2024/10/12/design-your-organization-for-the-conflicts-you-want-to-hear-about/\",\n",
    "    # \"https://peterszasz.com/engineering-managers-guide-to-effective-annual-feedback/\",\n",
    "    \"https://dennisnerush.medium.com/my-top-10-favorite-leadership-and-management-books-87178902826e\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a memoizing decorator that can be applied to a function\n",
    "# to cache the results of the function calls.\n",
    "def memoize(func):\n",
    "    cache = {}\n",
    "    def wrapper(*args, **kwargs):\n",
    "        key = str(args) + str(kwargs)\n",
    "        if key not in cache:\n",
    "            cache[key] = func(*args, **kwargs)\n",
    "        return cache[key]\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize\n",
    "def fetch_url(url):\n",
    "    headers = { \"Accept\": \"application/json\" }\n",
    "    response = requests.get(f\"https://r.jina.ai/{url}\", headers=headers)\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [fetch_url(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\", \n",
    "        \"\"\"You are an expert content strategist specializing in creating engaging educational content.\n",
    "        Your strength lies in breaking down complex topics into clear, relatable concepts while maintaining intellectual depth.\n",
    "        \n",
    "        Approach the analysis with:\n",
    "        1. Systems thinking - identify interconnections and patterns\n",
    "        2. Multi-level abstraction - from high-level principles to practical implementation\n",
    "        3. Engaging storytelling - find hooks and analogies that make concepts stick\n",
    "        4. Dialectical thinking - explore tensions and competing viewpoints\n",
    "        \n",
    "        Structure your analysis in this exact format:\n",
    "    \n",
    "        === CONCEPTS ===\n",
    "        [Each concept includes 3 depth levels marked with -]\n",
    "        ### [Concept Name]\n",
    "        - Strategic: [High level insight]\n",
    "        - Tactical: [Mid level approach] \n",
    "        - Practice: [Concrete examples]\n",
    "    \n",
    "        === HOOKS ===\n",
    "        [Each hook includes story + debate]\n",
    "        ### [Topic]\n",
    "        Story: [Engaging narrative]\n",
    "        Debate: [Key discussion points]\n",
    "    \n",
    "        === SEGMENTS ===\n",
    "        [List of main segments, one per line]\"\"\",\n",
    "    ),\n",
    "    (\n",
    "        \"human\", \n",
    "        \"\"\"Analyze these articles through multiple lenses to create rich podcast material:\n",
    "    \n",
    "        {article_contents}\n",
    "    \n",
    "        Create a layered analysis that:\n",
    "        1. Breaks down complex ideas through progressive levels of detail\n",
    "        2. Identifies natural conversation flows and engaging discussion points\n",
    "        3. Maps out competing viewpoints and their nuances\n",
    "        4. Groups related concepts into potential podcast segments\n",
    "        \"\"\",\n",
    "    ),\n",
    "])\n",
    "\n",
    "model = GoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=api_key)\n",
    "\n",
    "content_analysis_chain = content_analysis_prompt | model | StrOutputParser()\n",
    "\n",
    "# Usage\n",
    "article_contents = \"\\n\\n\".join([x['data']['content'] for x in content])\n",
    "result = content_analysis_chain.invoke({\n",
    "    \"article_contents\": article_contents,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PodcastSegment(BaseModel):\n",
    "    speaker: str = Field(description=\"HOST1 or HOST2\")\n",
    "    tone: str = Field(description=\"EXCITED|CALM|SERIOUS|THOUGHTFUL\")\n",
    "    text: str = Field(description=\"Raw text content\")\n",
    "    pace: str = Field(description=\"FAST|MEDIUM|SLOW\")\n",
    "    emphasis_words: List[str] = Field(description=\"Words to emphasize\")\n",
    "    pause_after: int = Field(description=\"Pause duration in ms\")\n",
    "\n",
    "class PodcastScript(BaseModel):\n",
    "    title: str\n",
    "    segments: List[PodcastSegment]\n",
    "\n",
    "podcast_script_parser = PydanticOutputParser(pydantic_object=PodcastScript)\n",
    "podcast_script_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\", \n",
    "        \"\"\"\n",
    "        You are an expert podcast host duo creating deep-dive episodes. Structure your conversation to:\n",
    "    \n",
    "        1. Start with a hook that captures attention\n",
    "        2. Layer concepts from surface to core insights\n",
    "        3. Use the Feynman technique to break down complex ideas\n",
    "        4. Challenge assumptions and explore counterpoints\n",
    "        5. Share concrete examples and case studies\n",
    "        6. Connect ideas across different contexts\n",
    "        7. End with actionable takeaways\n",
    "    \n",
    "        You are an expert podcast host duo creating full-length episodes. Generate a complete 5-30 minute episode with:\n",
    "\n",
    "        1. Opening [2-3 segments]\n",
    "        - Hook and episode preview\n",
    "        - Quick host banter\n",
    "        - Topic introduction\n",
    "    \n",
    "        2. Main Discussion [5-20 segments]\n",
    "        - Layer 1: Surface overview\n",
    "        - Layer 2: Core concepts unpacked\n",
    "        - Layer 3: Deep analysis\n",
    "        - Layer 4: Implementation details\n",
    "        - Regular transitions between hosts\n",
    "        - Examples and case studies\n",
    "        - Counterpoints and debates\n",
    "    \n",
    "        3. Closing [3-4 segments]\n",
    "        - Key takeaways\n",
    "        - Action items\n",
    "    \n",
    "        Each segment should be 1-2 minutes of spoken content.\n",
    "        Create a natural flow between segments:\n",
    "        - Build on previous points\n",
    "        - Ask probing questions\n",
    "        - Share relevant examples\n",
    "        - Challenge and debate ideas\n",
    "        - Synthesize insights\n",
    "        \n",
    "        Format each segment as:\n",
    "        {format_instructions}\n",
    "        \"\"\",\n",
    "    ),\n",
    "    (\n",
    "        \"human\", \n",
    "        \"\"\"Generate a podcast script using:\n",
    "        # Analysis result\n",
    "        {analysis_result}\n",
    "        \n",
    "        # Original content\n",
    "        {article_contents}\n",
    "        \"\"\",\n",
    "    ),\n",
    "])\n",
    "\n",
    "script_chain = (\n",
    "    podcast_script_prompt.partial(format_instructions=podcast_script_parser.get_format_instructions())\n",
    "    | model\n",
    "    | podcast_script_parser\n",
    ")\n",
    "script = script_chain.invoke({ \"analysis_result\": result, \"article_contents\": article_contents })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(script.segments))\n",
    "print(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from google.cloud import texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSEngine:\n",
    "    def __init__(self):\n",
    "        self.client = texttospeech.TextToSpeechClient()\n",
    "        self.voices = {\n",
    "            'HOST1': texttospeech.VoiceSelectionParams(\n",
    "                language_code='en-US',\n",
    "                name='en-US-Neural2-I',\n",
    "                ssml_gender=texttospeech.SsmlVoiceGender.MALE\n",
    "            ),\n",
    "            'HOST2': texttospeech.VoiceSelectionParams(\n",
    "                language_code='en-US',\n",
    "                name='en-US-Neural2-F',\n",
    "                ssml_gender=texttospeech.SsmlVoiceGender.FEMALE\n",
    "            )\n",
    "        }\n",
    "        self.audio_config = texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3,\n",
    "            effects_profile_id=['headphone-class-device']\n",
    "        )\n",
    "\n",
    "    def process_segment(self, segment: PodcastSegment) -> bytes:\n",
    "        ssml = self.generate_ssml(segment)\n",
    "        return self.synthesize_speech(ssml, segment.speaker)\n",
    "\n",
    "    def get_pace(self, pace: str) -> str:\n",
    "        pace_values = {\n",
    "            \"FAST\": \"120%\",\n",
    "            \"MEDIUM\": \"100%\",\n",
    "            \"SLOW\": \"85%\",\n",
    "            \"VERY_SLOW\": \"75%\",\n",
    "            \"VERY_FAST\": \"140%\"\n",
    "        }\n",
    "        return pace_values.get(pace, \"100%\")\n",
    "\n",
    "    def get_tone(self, tone: str) -> str:\n",
    "        tone_values = {\n",
    "            \"EXCITED\": \"+4st\",\n",
    "            \"CALM\": \"-1st\",\n",
    "            \"SERIOUS\": \"-2st\",\n",
    "            \"THOUGHTFUL\": \"+0st\",\n",
    "            \"WORRIED\": \"-3st\",\n",
    "            \"INTENSE\": \"+2st\",\n",
    "            \"ENTHUSIASTIC\": \"+3st\",\n",
    "            \"SKEPTICAL\": \"-1.5st\",\n",
    "            \"CURIOUS\": \"+1st\",\n",
    "            \"AMUSED\": \"+2.5st\"\n",
    "        }\n",
    "        return tone_values.get(tone, \"+0st\")\n",
    "\n",
    "    def generate_ssml(self, segment: PodcastSegment) -> str:\n",
    "        text = segment.text\n",
    "        for word in segment.emphasis_words:\n",
    "            text = text.replace(word, f'<emphasis level=\"strong\">{word}</emphasis>')\n",
    "\n",
    "        ssml = f'<speak><prosody rate=\"{self.get_pace(segment.pace)}\" pitch=\"{self.get_tone(segment.tone)}\">{text}</prosody>'\n",
    "        ssml += f'<break time=\"{segment.pause_after}ms\"/></speak>'\n",
    "        return ssml\n",
    "\n",
    "    def synthesize_speech(self, ssml: str, speaker: str) -> bytes:\n",
    "        synthesis_input = texttospeech.SynthesisInput(ssml=ssml)\n",
    "        response = self.client.synthesize_speech(\n",
    "            input=synthesis_input,\n",
    "            voice=self.voices[speaker],\n",
    "            audio_config=self.audio_config\n",
    "        )\n",
    "        return response.audio_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_engine = TTSEngine()\n",
    "audio_segments = [tts_engine.process_segment(segment) for segment in script.segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = \"generated_podcasts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate timestamp for unique filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "podcast_path = f\"{output_dir}/podcast_{timestamp}.mp3\"\n",
    "\n",
    "# Combine segments directly\n",
    "combined = AudioSegment.empty()\n",
    "for segment in audio_segments:\n",
    "    segment_audio = AudioSegment.from_mp3(BytesIO(segment))\n",
    "    combined += segment_audio\n",
    "\n",
    "# Save final podcast\n",
    "combined.export(podcast_path, format=\"mp3\")\n",
    "\n",
    "# Play in notebook\n",
    "display(Audio(podcast_path, autoplay=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
